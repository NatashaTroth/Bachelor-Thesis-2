

The goal of this paper is to identify, which time delta for aggregation is ideal to construct distinct clusters from smartphone sensor and usage data. The data for this experiment was collected for the upcoming SmartEater \footnote{\url{https://sites.google.com/site/eatingandanxietylab/resources/smarteater}} mobile health app. The goal of this app is to present the user with content-dependent feedback, with the hope to prevent food craving episodes. By evaluating the user's behaviour (through smartphone sensor and usage data), the app predicts eating crises through stress, therefore eliminating the need of intense user input. 

Various sensor and usage data was recorded for the SmartEater project, by the 46 testers' smartphones (for different periods of time). The columns of the data were organised as follows (N is the number of times the data was recorded in the time period, app usage in percent of lag-interval minutes):
 

\begin{itemize}
	\item TIME: timestamp, when the data was aggregated (format: YYYY-DD-MM hh:mm:ss)
	\item ACC (1-N): values received from the accelerometer (average jerk). According to the Android developers documentation\footnote{\url{https://developer.android.com/guide/topics/sensors/sensors_motion}}, the accelerometer (acceleration sensor) records the acceleration (including the force of gravity) enforced onto the smartphone. 
	\item AUDIO (1-N): volume of the audio 
	\item SCRN (1-N): percentage of screen-on-time
	\item NOTIF (1-N): number of notifications
	\item LIGHT (1-N): (environment) light sensor values
	\item APP\_COM (1-N): app usage in the category \textit{communication} 
	\item APP\_VID (1-N): app usage in the category \textit{video players}
	\item APP\_OTHER (1-N): app usage of all other categories (excluding \textit{video players} and \textit{communication})
\end{itemize}


The recorded smartphone sensor and usage data was aggregated into multiple .csv (Comma-Separated Values\footnote{\url{https://tools.ietf.org/html/rfc4180}}) files. Furthermore, these files were distinguished into folders, according to their time delta. Two different time lengths were used:

\begin{itemize}
  \item 1h: The data was aggregated in 2.5 hour intervals, whereby each row contained data from an aggregation of 1 hour, in four 15 minute lags.
  \item 3h: The data was aggregated in 1.5 hour intervals, whereby each row contained data from an aggregation of 3 hours, in six 30 minute lags.
\end{itemize}

Each row contains the data value of a specific test user for one of the time periods (e.g. 1h or 3h).

Python was used to conduct the experiment, more specifically using the Anaconda\footnote{\url{https://www.anaconda.com/}} Python distribution platform for data science. The scikit-learn\footnote{\url{https://scikit-learn.org/stable/index.html}} (short sklearn) Python package provides simple tools for predictive data analysis and was used for data preparation, dimensionality reduction, and clustering.

