% in clustering after dim red

Dimensionality reduction was implemented to reduce the number of dimensions (number of attributes, so in this case number of columns). Principal Components Analysis (PCA) and T-SNE, as described in section \ref{section:DimensionalityReduction}, were used to reduce the dimensionality of the data set. PCA was the initial approach used in the experiment. The sklearn PCA\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}} function was used to reduce the number of dimensions to 2 (for 2D scatterplots) or 3 (for 3D scatterplots). The PCA allowed 65\%-95\% (depending on data preparation type) of the data's important structures to be accounted for in only the first two or three principle components. As can be seen in figure \textbf{TODO: figures}, the resulting data from these components, didn't show any meaningful patterns. 
%&todo - this is because not linear data and pca is linear. 
The t-SNE approach proved to be more significant.
