% in clustering after dim red

Dimensionality reduction was implemented to reduce the number of dimensions (number of attributes, so in this case number of columns). Principal Components Analysis (PCA) and t-SNE, as described in section \ref{section:DimensionalityReduction}, were used to reduce the dimensionality of the data set. PCA was the initial approach used in the experiment. The sklearn PCA\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}} function was used to reduce the number of dimensions to 2, which simplified visualisation in 2D scatterplots. The PCA allowed 65\%-95\% (depending on data preparation type) of the data's important structures to be accounted for in only the first two or three principle components. As can be seen in figure \textbf{TODO: figures}, the resulting data from these components, didn't show any significant clusters, in comparison to the t-SNE results.
%&todo - this is because not linear data and pca is linear.
%todo - mention 3D or just stick to 2D

The t-SNE approach proved to be more significant.

Since the results 


