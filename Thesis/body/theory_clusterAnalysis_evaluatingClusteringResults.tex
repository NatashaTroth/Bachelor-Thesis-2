 \textcite{han2011data}[396, 399, 401] point out, that the cluster quality needs to be evaluated. Generally, there are two ways to measure the quality of clustering: extrinsic methods and intrinsic methods. In extrinsic methods (or supervised methods), there is a ground truth available. This ground truth is usually produced by experts (humans). Intrinsic methods are used, when there is no ground truth available. In intrinsic methods, the clusters are evaluated by how well they are separated from one another and how compact they are (e.g. \textit{silhouette coefficient}). The experiment conducted in this paper uses intrinsic methods, since there is no ground truth for comparison.

\subsubsection{Silhouette Coefficient}
\label{section:silhouetteCoefficient}
In his paper, \textcite{rousseeuw1987silhouettes}[55-56, 59] proposes a new graphical display using silhouettes, to help determine how well objects belong to their assigned clusters. It can be used to interpret and validate the results of clustering. It is also utilised to compare clusters created by different algorithms, the input data being the same.

The formula is as follows:
With the use of silhouettes, the author's goal is to find out, if the quality of the clusters is high. Hence, the dissimilarities of the objects within a cluster are small, and the dissimilarities are large compared to the objects in other clusters. For each object \textit{i} in cluster \textit{A}, the value \textit{s(i)} is calculated. The variable \textit{a(i)} contains the average dissimilarity of the object \textit{i} to each other object in the same cluster. If there are no other objects in the cluster, \textit{s(i)} is set to zero (most neutral value). The variable \textit{b(i)} is determined by firstly calculating the average dissimilarity for each neighbouring cluster that isn't \textit{A}. The shortest of these values, therefore the next closest cluster to \textit{A}, is then assigned to \textit{b(i)}. This cluster may be seen as the next best choice for \textit{i}. \textit{b(i)} can only be calculated, if there are other clusters besides \textit{A}. The formula for \textit{s(i)} is as follows:
\[
  s(i) = \frac{b(i) - a(i)}{max\{a(i), b(i)\}}  
\]
The resulting value \textit{s(i)} is a number in the range of \textit{-1 $\leq$ \textit{s(i)} $\leq$ 1}:

\[ s(i) =
\begin{cases}
  1 - a(i)/b(i)       & \quad \text{if } a(i) < b(i)\\
  0       & \quad \text{if } a(i) = b(i)\\
b(i)/a(i) - 1      & \quad \text{if } a(i) > b(i)

\end{cases}
\]
A \textit{s(i)} value close to 1 reveals, that the dissimilarity within a cluster is smaller than the dissimilarity to the neighbouring cluster. Therefore it suggests, that the assignment of that object is good, since it is most likely the most suitable cluster for \textit{i} (well-classified). A \textit{s(i)} value close to 0 means, that \textit{a(i)} and \textit{b(i)} are almost equal and it is uncertain whether cluster \textit{A} or its neighbour is a more suitable fit. If \textit{s(i)} is near -1, then the dissimilarity within a cluster is larger than the dissimilarity to the next closest cluster. Thus, it would have been more natural to assign \textit{i} to the neighbouring cluster, since it is closer to it (misclassified).

The \textit{average silhouette width} can be calculated for single clusters. It is established by calculating the average of all objects that belong to said cluster. An average score can also be calculated from each object \textit{i} for the whole chart (dataset), the so called \textit{overall average silhouette width}. 


\subsubsection{Davies-Bouldin Index}
A second cluster evaluation method is the Davies-Bouldin Index, which was proposed by \textcite{DaviesBouldin}[224-227]. The succeeding formula describes the average similarity of a cluster with the cluster that is most similar to it (\textit{R\textsubscript{ij}} ).
\textit{i} and \textit{j} represent the determined clusters, \textit{S\textsubscript{i}} and \textit{S\textsubscript{j}} stand for the dispersions of the clusters, and \textit{M\textsubscript{ij}} is the distance between the two cluster centroids. 

\[
R_{ij} = \frac{S_i + S_j}{M_{ij}}  
\]

The Davies-Bouldin Index equals:
\[
\overline{R} = \frac{1}{N}\sum_{i=1}^{N}R_i
\]

This metric can be used to compare clustering results. The lower of the two \textit{\=R} values indicates the better partitioning.

\subsubsection{Caliński-Harabasz Index}
As a third evaluation score, \textcite{calinskiHarabasz}[3, 7, 10-12, 25] is used to evaluate and compare the resulting clusters in the experiment. 
The Caliński-Harabasz Index or Variance Ratio Criterion (VRC) is calculated as follows, where \textit{n} is the number of points, \textit{k} is the number of clusters, \textit{WGSS} is the within-group (cluster) sum of squares, and \textit{BGSS} is the between-group (cluster) sum of squares.

\[
VRC = \frac{BGSS}{k-1}/\frac{WGSS}{n-k}
\]
If \textit{k} is not known, it is set to 2, then 3, and so on. The density of the clusters can be calculated with the sums of the squared distances from the cluster centroids to the points. The more natural the clusterings are, the higher VRC will be, since the variation within the cluster is lower.